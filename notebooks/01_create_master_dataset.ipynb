{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 看護師離職率データセット作成（ETL完全版）\n",
    "\n",
    "このノートブックは、手作業によるデータ作成と同等の品質（正確な数値、適切な単位）を自動化するためのものです。\n",
    "特に**「沖縄県のデータ異常」「年収の単位変換」「家賃の民営借家指定」**などの重要ロジックが実装されています。\n",
    "\n",
    "## 前提\n",
    "- 元データ（CSV/Excel）が `../data/raw/` に配置されていること。\n",
    "- 出力先は `../data/processed/` です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Configuration:\n",
      "  Input (Raw): /Users/hideomi.h/nurse-turnover-analysis/data/raw\n",
      "  Output (Processed): /Users/hideomi.h/nurse-turnover-analysis/data/processed\n",
      "\n",
      "--- Normalize Test ---\n",
      "'青　森' -> '青森県'\n",
      "'東京' -> '東京都'\n",
      "'神奈川県' -> '神奈川県'\n",
      "'全国' -> 'nan'\n",
      "'大阪' -> '大阪府'\n",
      "'福岡' -> '福岡県'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. プロジェクト設定\n",
    "# ---------------------------------------------------------\n",
    "# パス定義 (notebooks/ からの相対パス)\n",
    "DIR_RAW = '../data/raw'\n",
    "DIR_PROCESSED = '../data/processed'\n",
    "DIR_INTERMEDIATE = os.path.join(DIR_PROCESSED, 'intermediate')\n",
    "\n",
    "# 出力ディレクトリの作成\n",
    "os.makedirs(DIR_INTERMEDIATE, exist_ok=True)\n",
    "\n",
    "print(f\"Directory Configuration:\")\n",
    "print(f\"  Input (Raw): {os.path.abspath(DIR_RAW)}\")\n",
    "print(f\"  Output (Processed): {os.path.abspath(DIR_PROCESSED)}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. 共通関数：都道府県名の正規化 (仕様書 2.1準拠)\n",
    "# ---------------------------------------------------------\n",
    "def normalize_prefecture(text):\n",
    "    \"\"\"\n",
    "    あらゆる表記の都道府県名を統一フォーマット（末尾に都府県付き）に変換する。\n",
    "    全国、計、不明などは欠損(NaN)にする。\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return np.nan\n",
    "    \n",
    "    # クリーニング\n",
    "    text = str(text).replace(\" \", \"\").replace(\"　\", \"\").strip()\n",
    "    \n",
    "    # 除外キーワード (仕様書 2.1)\n",
    "    exclude_keywords = ['全国', '計', '未回答', '無回答', '不明', '総数']\n",
    "    if any(keyword == text for keyword in exclude_keywords): \n",
    "        return np.nan\n",
    "    if text in exclude_keywords:\n",
    "        return np.nan\n",
    "\n",
    "    # 接尾辞ロジック\n",
    "    if text == \"北海道\":\n",
    "        return text\n",
    "    elif text == \"東京\":\n",
    "        return \"東京都\"\n",
    "    elif text in [\"大阪\", \"京都\"]:\n",
    "        return text + \"府\"\n",
    "    \n",
    "    # 既に末尾が正しいかチェック\n",
    "    if text.endswith((\"都\", \"道\", \"府\", \"県\")):\n",
    "        return text\n",
    "    \n",
    "    # それ以外は「県」を補完 (例: 青森 -> 青森県)\n",
    "    return text + \"県\"\n",
    "\n",
    "# テスト実行\n",
    "print(\"\\n--- Normalize Test ---\")\n",
    "test_samples = [\"青　森\", \"東京\", \"神奈川県\", \"全国\", \"大阪\", \"福岡\"]\n",
    "for t in test_samples:\n",
    "    print(f\"'{t}' -> '{normalize_prefecture(t)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 厚労省_医療施設調査_病床規模_2024.csv\n",
      "  -> Raw shape: (1965, 32)\n",
      "  -> Columns identified:\n",
      "     Pref: 都道府県－指定都市・特別区・中核市（再掲）\n",
      "     Size: 病床の規模_001\n",
      "     Value: 一般病院（総数）\n",
      "  -> Saved: ../data/processed/intermediate/temp_large_hospitals.csv (Rows: 130)\n",
      "  prefecture  large_hospital_count\n",
      "0        三重県                     4\n",
      "1        京都府                    10\n",
      "2        佐賀県                     3\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 1: 医療施設調査（病床規模）の加工\n",
    "# Target: 厚労省_医療施設調査_病床規模_2024.csv\n",
    "# Logic: Header=12(13行目), 縦持ちデータをフィルタして集計\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "FILE_BEDS = os.path.join(DIR_RAW, '厚労省_医療施設調査_病床規模_2024.csv')\n",
    "\n",
    "try:\n",
    "    print(f\"Processing: {os.path.basename(FILE_BEDS)}\")\n",
    "    \n",
    "    # 1. 読み込み (Header位置固定: 13行目=Index 12)\n",
    "    # BOM付きCSVのため utf-8-sig を指定\n",
    "    df_beds = pd.read_csv(FILE_BEDS, encoding='utf-8-sig', header=12)\n",
    "    \n",
    "    print(f\"  -> Raw shape: {df_beds.shape}\")\n",
    "    \n",
    "    # 2. 列名の特定（テキストダンプに基づく）\n",
    "    # 都道府県: \"都道府県－指定都市・特別区・中核市（再掲）\"\n",
    "    # 病床カテゴリ: \"病床の規模_001\"\n",
    "    # 値: \"一般病院（総数）\"\n",
    "    \n",
    "    col_pref = [c for c in df_beds.columns if '都道府県' in c and 'コード' not in c][0]\n",
    "    col_size = [c for c in df_beds.columns if '病床の規模' in c and 'コード' not in c][0]\n",
    "    col_val = [c for c in df_beds.columns if '一般病院' in c and '総数' in c][0]\n",
    "    \n",
    "    print(f\"  -> Columns identified:\")\n",
    "    print(f\"     Pref: {col_pref}\")\n",
    "    print(f\"     Size: {col_size}\")\n",
    "    print(f\"     Value: {col_val}\")\n",
    "\n",
    "    # 3. 都道府県の正規化\n",
    "    df_beds['prefecture'] = df_beds[col_pref].apply(normalize_prefecture)\n",
    "    # 全国や再掲（政令指定都市など）を除外して、純粋な47都道府県のみ残す\n",
    "    df_beds = df_beds.dropna(subset=['prefecture'])\n",
    "    \n",
    "    # 4. 500床以上の行を抽出\n",
    "    # ターゲット: 500～599, 600～699, 700～799, 800～899, 900床以上\n",
    "    target_sizes = [\n",
    "        \"500～599床\", \"600～699床\", \"700～799床\", \"800～899床\", \"900床以上\"\n",
    "    ]\n",
    "    # 文字列の部分一致やリスト判定でフィルタ\n",
    "    mask_large = df_beds[col_size].astype(str).str.strip().isin(target_sizes)\n",
    "    df_large = df_beds[mask_large].copy()\n",
    "    \n",
    "    # 5. 数値化と集計\n",
    "    # \"-\" や \",\" を処理\n",
    "    def clean_num(x):\n",
    "        s = str(x).replace(',', '').strip()\n",
    "        if s in ['-', '…', '...', '***', 'X']:\n",
    "            return 0\n",
    "        try:\n",
    "            return int(s)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    df_large['val_numeric'] = df_large[col_val].apply(clean_num)\n",
    "    \n",
    "    # 都道府県ごとに合計 (group by prefecture)\n",
    "    df_beds_out = df_large.groupby('prefecture', as_index=False)['val_numeric'].sum()\n",
    "    df_beds_out = df_beds_out.rename(columns={'val_numeric': 'large_hospital_count'})\n",
    "    \n",
    "    # 6. 保存\n",
    "    out_path = os.path.join(DIR_INTERMEDIATE, 'temp_large_hospitals.csv')\n",
    "    df_beds_out.to_csv(out_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"  -> Saved: {out_path} (Rows: {len(df_beds_out)})\")\n",
    "    print(df_beds_out.head(3))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in Step 1: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 総務省_社会生活基本調査_通勤時間_2022.xlsx\n",
      "Error in Step 2: list index out of range\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 2: 通勤時間の加工\n",
    "# Target: 総務省_社会生活基本調査_通勤時間_2022.xlsx\n",
    "# Logic: \"1.24\" (1時間24分) -> 84分 に変換 (60進法)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "FILE_COMMUTE = os.path.join(DIR_RAW, '総務省_社会生活基本調査_通勤時間_2022.xlsx')\n",
    "\n",
    "def convert_hours_minutes_to_minutes(val):\n",
    "    if pd.isna(val): return np.nan\n",
    "    try:\n",
    "        val = float(val)\n",
    "        hours = int(val)\n",
    "        # 小数部分を \"分\" として取り出す (0.24 -> 24)\n",
    "        minutes = int(round((val - hours) * 100))\n",
    "        return hours * 60 + minutes\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "try:\n",
    "    print(f\"Processing: {os.path.basename(FILE_COMMUTE)}\")\n",
    "    \n",
    "    # ヘッダー探索\n",
    "    df_temp = pd.read_excel(FILE_COMMUTE, header=None, nrows=20)\n",
    "    header_row = df_temp.index[df_temp.apply(lambda x: x.astype(str).str.contains('都道府県|通勤').any(), axis=1)][0]\n",
    "    df_commute = pd.read_excel(FILE_COMMUTE, header=header_row)\n",
    "    \n",
    "    # 列特定\n",
    "    col_pref = [c for c in df_commute.columns if '都道府県' in str(c)][0]\n",
    "    # 値の列: \"通勤時間\" や \"総数\"、あるいは一番右の列を狙う\n",
    "    col_val = [c for c in df_commute.columns if '通勤' in str(c) or '総数' in str(c)][-1] \n",
    "    \n",
    "    # 正規化\n",
    "    df_commute['prefecture'] = df_commute[col_pref].apply(normalize_prefecture)\n",
    "    df_commute = df_commute.dropna(subset=['prefecture'])\n",
    "    \n",
    "    # 時間変換\n",
    "    df_commute['commute_time'] = df_commute[col_val].apply(convert_hours_minutes_to_minutes)\n",
    "    \n",
    "    # 保存\n",
    "    df_commute_out = df_commute[['prefecture', 'commute_time']].copy()\n",
    "    out_path = os.path.join(DIR_INTERMEDIATE, 'temp_commute.csv')\n",
    "    df_commute_out.to_csv(out_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"  -> Saved: {out_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in Step 2: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 厚労省_一般職業紹介状況_有効求人倍率_2025.xlsx\n",
      "  -> Header found at row index: 1\n",
      "  -> Date columns identified: Year='西暦', Month='Unnamed: 2'\n",
      "  -> Extracted rows: 3 (Expected: 12)\n",
      "  -> Saved: ../data/processed/intermediate/temp_job_ratio.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 3.5: 有効求人倍率 (2023年度平均) の算出\n",
    "# Target: 厚労省_一般職業紹介状況_有効求人倍率_2025.xlsx\n",
    "# Logic: \"2023年4月\"〜\"2024年3月\" の行を特定し、その平均値を算出する\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "FILE_JOB = os.path.join(DIR_RAW, '厚労省_一般職業紹介状況_有効求人倍率_2025.xlsx')\n",
    "\n",
    "try:\n",
    "    print(f\"Processing: {os.path.basename(FILE_JOB)}\")\n",
    "    \n",
    "    # 1. ヘッダー行を探す（都道府県名が並んでいる行）\n",
    "    df_temp = pd.read_excel(FILE_JOB, header=None, nrows=50)\n",
    "    header_row_idx = df_temp.index[df_temp.apply(lambda x: x.astype(str).str.contains('北海道').any(), axis=1)][0]\n",
    "    print(f\"  -> Header found at row index: {header_row_idx}\")\n",
    "    \n",
    "    # 2. 本読み込み\n",
    "    df_job = pd.read_excel(FILE_JOB, header=header_row_idx)\n",
    "    \n",
    "    # 3. 年・月の列を特定（画像を見ると左端に年と月がある）\n",
    "    # 列名が不明確な場合が多いので、データの中身で列を特定する\n",
    "    col_year = None\n",
    "    col_month = None\n",
    "    \n",
    "    for col in df_job.columns[:10]: # 左側の10列くらいを調査\n",
    "        sample_vals = df_job[col].astype(str).head(10).tolist()\n",
    "        if any('年' in v for v in sample_vals if v != 'nan'):\n",
    "            if col_year is None: col_year = col\n",
    "        if any('月' in v for v in sample_vals if v != 'nan'):\n",
    "            if col_month is None: col_month = col\n",
    "            \n",
    "    if not col_year or not col_month:\n",
    "        # 見つからない場合のフォールバック（画像の配置から推測）\n",
    "        col_year = df_job.columns[0]\n",
    "        col_month = df_job.columns[2] # 間に元号列があると仮定\n",
    "    \n",
    "    print(f\"  -> Date columns identified: Year='{col_year}', Month='{col_month}'\")\n",
    "\n",
    "    # 4. フィルタリング (2023年度 = 2023.4 ~ 2024.3)\n",
    "    # スペース除去して型統一\n",
    "    df_job[col_year] = df_job[col_year].astype(str).str.replace(' ', '').str.replace('　', '')\n",
    "    df_job[col_month] = df_job[col_month].astype(str).str.replace(' ', '').str.replace('　', '')\n",
    "    \n",
    "    # 条件作成\n",
    "    mask_2023 = (df_job[col_year] == '2023年') & (df_job[col_month].isin([f'{i}月' for i in range(4, 13)]))\n",
    "    mask_2024 = (df_job[col_year] == '2024年') & (df_job[col_month].isin(['1月', '2月', '3月']))\n",
    "    \n",
    "    df_fy2023 = df_job[mask_2023 | mask_2024].copy()\n",
    "    print(f\"  -> Extracted rows: {len(df_fy2023)} (Expected: 12)\")\n",
    "    \n",
    "    if len(df_fy2023) == 0:\n",
    "        raise ValueError(\"No rows matched for FY2023. Check date formats.\")\n",
    "\n",
    "    # 5. 都道府県ごとの平均を算出\n",
    "    valid_means = {}\n",
    "    for col in df_fy2023.columns:\n",
    "        pref_name = normalize_prefecture(str(col))\n",
    "        if isinstance(pref_name, str):\n",
    "            # 数値化して平均\n",
    "            vals = pd.to_numeric(df_fy2023[col], errors='coerce')\n",
    "            valid_means[pref_name] = vals.mean()\n",
    "            \n",
    "    df_job_out = pd.DataFrame(list(valid_means.items()), columns=['prefecture', 'job_openings_ratio'])\n",
    "    \n",
    "    # 保存\n",
    "    out_path = os.path.join(DIR_INTERMEDIATE, 'temp_job_ratio.csv')\n",
    "    df_job_out.to_csv(out_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"  -> Saved: {out_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in Step 3.5: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 厚労省_一般職業紹介状況_有効求人倍率_2025.xlsx\n",
      "  -> Header found at row index: 1\n",
      "  -> Date columns identified: Year='西暦', Month='Unnamed: 2'\n",
      "  -> Extracted rows: 3 (Expected: 12)\n",
      "  -> Saved: ../data/processed/intermediate/temp_job_ratio.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 3.5: 有効求人倍率 (2023年度平均) の算出\n",
    "# Target: 厚労省_一般職業紹介状況_有効求人倍率_2025.xlsx\n",
    "# Logic: \"2023年4月\"〜\"2024年3月\" の行を特定し、その平均値を算出する\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "FILE_JOB = os.path.join(DIR_RAW, '厚労省_一般職業紹介状況_有効求人倍率_2025.xlsx')\n",
    "\n",
    "try:\n",
    "    print(f\"Processing: {os.path.basename(FILE_JOB)}\")\n",
    "    \n",
    "    # 1. ヘッダー行を探す（都道府県名が並んでいる行）\n",
    "    df_temp = pd.read_excel(FILE_JOB, header=None, nrows=50)\n",
    "    header_row_idx = df_temp.index[df_temp.apply(lambda x: x.astype(str).str.contains('北海道').any(), axis=1)][0]\n",
    "    print(f\"  -> Header found at row index: {header_row_idx}\")\n",
    "    \n",
    "    # 2. 本読み込み\n",
    "    df_job = pd.read_excel(FILE_JOB, header=header_row_idx)\n",
    "    \n",
    "    # 3. 年・月の列を特定（画像を見ると左端に年と月がある）\n",
    "    # 列名が不明確な場合が多いので、データの中身で列を特定する\n",
    "    col_year = None\n",
    "    col_month = None\n",
    "    \n",
    "    for col in df_job.columns[:10]: # 左側の10列くらいを調査\n",
    "        sample_vals = df_job[col].astype(str).head(10).tolist()\n",
    "        if any('年' in v for v in sample_vals if v != 'nan'):\n",
    "            if col_year is None: col_year = col\n",
    "        if any('月' in v for v in sample_vals if v != 'nan'):\n",
    "            if col_month is None: col_month = col\n",
    "            \n",
    "    if not col_year or not col_month:\n",
    "        # 見つからない場合のフォールバック（画像の配置から推測）\n",
    "        col_year = df_job.columns[0]\n",
    "        col_month = df_job.columns[2] # 間に元号列があると仮定\n",
    "    \n",
    "    print(f\"  -> Date columns identified: Year='{col_year}', Month='{col_month}'\")\n",
    "\n",
    "    # 4. フィルタリング (2023年度 = 2023.4 ~ 2024.3)\n",
    "    # スペース除去して型統一\n",
    "    df_job[col_year] = df_job[col_year].astype(str).str.replace(' ', '').str.replace('　', '')\n",
    "    df_job[col_month] = df_job[col_month].astype(str).str.replace(' ', '').str.replace('　', '')\n",
    "    \n",
    "    # 条件作成\n",
    "    mask_2023 = (df_job[col_year] == '2023年') & (df_job[col_month].isin([f'{i}月' for i in range(4, 13)]))\n",
    "    mask_2024 = (df_job[col_year] == '2024年') & (df_job[col_month].isin(['1月', '2月', '3月']))\n",
    "    \n",
    "    df_fy2023 = df_job[mask_2023 | mask_2024].copy()\n",
    "    print(f\"  -> Extracted rows: {len(df_fy2023)} (Expected: 12)\")\n",
    "    \n",
    "    if len(df_fy2023) == 0:\n",
    "        raise ValueError(\"No rows matched for FY2023. Check date formats.\")\n",
    "\n",
    "    # 5. 都道府県ごとの平均を算出\n",
    "    valid_means = {}\n",
    "    for col in df_fy2023.columns:\n",
    "        pref_name = normalize_prefecture(str(col))\n",
    "        if isinstance(pref_name, str):\n",
    "            # 数値化して平均\n",
    "            vals = pd.to_numeric(df_fy2023[col], errors='coerce')\n",
    "            valid_means[pref_name] = vals.mean()\n",
    "            \n",
    "    df_job_out = pd.DataFrame(list(valid_means.items()), columns=['prefecture', 'job_openings_ratio'])\n",
    "    \n",
    "    # 保存\n",
    "    out_path = os.path.join(DIR_INTERMEDIATE, 'temp_job_ratio.csv')\n",
    "    df_job_out.to_csv(out_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"  -> Saved: {out_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in Step 3.5: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
